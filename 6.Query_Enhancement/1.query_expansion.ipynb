{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0bd5b5b",
   "metadata": {},
   "source": [
    "### Query Enhancement – Query Expansion Techniques\n",
    "\n",
    "In a RAG pipeline, the quality of the query sent to the retriever determines how good the retrieved context is — and therefore, how accurate the LLM’s final answer will be.\n",
    "\n",
    "That’s where Query Expansion / Enhancement comes in.\n",
    "\n",
    "#### 🎯 What is Query Enhancement?\n",
    "Query enhancement refers to techniques used to improve or reformulate the user query to retrieve better, more relevant documents from the knowledge base.\n",
    "It is especially useful when:\n",
    "\n",
    "- The original query is short, ambiguous, or under-specified\n",
    "- You want to broaden the scope to catch synonyms, related phrases, or spelling variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a240159",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "# from langchain.chat_models import init_chat_model\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableMap\n",
    "from pydantic import SecretStr\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6e2fef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ API keys loaded successfully\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STEP 3: Environment Setup\n",
    "Load API credentials securely from environment variables.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get Google API key with error handling\n",
    "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "if not GOOGLE_API_KEY:\n",
    "    raise ValueError(\"GOOGLE_API_KEY not found in environment variables\")\n",
    "\n",
    "print(\"✓ API keys loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d84745de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Gemini model initialized for reranking\n"
     ]
    }
   ],
   "source": [
    "# Initialize Google embeddings model for vector representation\n",
    "embedding_model = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/gemini-embedding-001\"\n",
    ")\n",
    "\n",
    "\n",
    "# Initialize Google's Gemini model for response generation\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash-exp\",    # Latest flash model\n",
    "    temperature=0,               # Deterministic output for consistency in ranking\n",
    "    max_tokens=None,            # Use model default token limit\n",
    "    timeout=None,               # No timeout limit for ranking requests\n",
    "    max_retries=2,              # Retry failed requests twice\n",
    ")\n",
    "\n",
    "print(\"✓ Gemini model initialized for reranking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1916b991",
   "metadata": {},
   "outputs": [],
   "source": [
    "## step1 : Load and split the dataset\n",
    "loader = TextLoader(\"langchain_crewai_dataset.txt\")\n",
    "raw_docs = loader.load()\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "chunks = splitter.split_documents(raw_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ccff90e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='like web search, calculators, code execution environments, and custom APIs. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Prompt engineering is central to LangChain’s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v1)\"),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='like web search, calculators, code execution environments, and custom APIs. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Prompt engineering is central to LangChain’s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v2)\"),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='like web search, calculators, code execution environments, and custom APIs. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Prompt engineering is central to LangChain’s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v3)\"),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='like web search, calculators, code execution environments, and custom APIs. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Prompt engineering is central to LangChain’s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v4)\"),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='like web search, calculators, code execution environments, and custom APIs. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Prompt engineering is central to LangChain’s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v5)\"),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='like web search, calculators, code execution environments, and custom APIs. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Prompt engineering is central to LangChain’s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v6)\"),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='like web search, calculators, code execution environments, and custom APIs. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Prompt engineering is central to LangChain’s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v7)\"),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='like web search, calculators, code execution environments, and custom APIs. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Prompt engineering is central to LangChain’s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v8)\"),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='like web search, calculators, code execution environments, and custom APIs. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Prompt engineering is central to LangChain’s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v9)\"),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='like web search, calculators, code execution environments, and custom APIs. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Prompt engineering is central to LangChain’s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another.'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and dynamically communicating with one another. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v10)\"),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v10)')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2f0b097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7d0ce039a0c0>, search_type='mmr', search_kwargs={'k': 5})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### step 2: Vector Store\n",
    "embedding_model=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectorstore=FAISS.from_documents(chunks,embedding_model)\n",
    "\n",
    "## step 3:MMR Retriever\n",
    "retriever=vectorstore.as_retriever(search_type=\"mmr\",search_kwargs={\"k\":5})\n",
    "retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8663d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing first batch of 5 chunks...\n",
      "Processing batch 2: chunks 5 to 10\n",
      "✓ Processed batch 2\n",
      "Processing batch 3: chunks 10 to 15\n",
      "✓ Processed batch 3\n",
      "Processing batch 4: chunks 15 to 20\n",
      "✓ Processed batch 4\n",
      "Processing batch 5: chunks 20 to 25\n",
      "✓ Processed batch 5\n",
      "Processing batch 6: chunks 25 to 30\n",
      "✓ Processed batch 6\n",
      "Processing batch 7: chunks 30 to 35\n",
      "✓ Processed batch 7\n",
      "Processing batch 8: chunks 35 to 40\n",
      "✓ Processed batch 8\n",
      "Processing batch 9: chunks 40 to 45\n",
      "✓ Processed batch 9\n",
      "Processing batch 10: chunks 45 to 50\n",
      "✓ Processed batch 10\n",
      "Processing batch 11: chunks 50 to 55\n",
      "✓ Processed batch 11\n",
      "Processing batch 12: chunks 55 to 60\n",
      "✓ Processed batch 12\n",
      "Processing batch 13: chunks 60 to 65\n",
      "✓ Processed batch 13\n",
      "Processing batch 14: chunks 65 to 70\n",
      "✓ Processed batch 14\n",
      "Processing batch 15: chunks 70 to 75\n",
      "✓ Processed batch 15\n",
      "Processing batch 16: chunks 75 to 80\n",
      "✓ Processed batch 16\n",
      "Processing batch 17: chunks 80 to 85\n",
      "✓ Processed batch 17\n",
      "Processing batch 18: chunks 85 to 90\n",
      "✓ Processed batch 18\n",
      "Processing batch 19: chunks 90 to 95\n",
      "✓ Processed batch 19\n",
      "Processing batch 20: chunks 95 to 100\n",
      "✓ Processed batch 20\n",
      "Processing batch 21: chunks 100 to 105\n",
      "✓ Processed batch 21\n",
      "Processing batch 22: chunks 105 to 110\n",
      "✓ Processed batch 22\n",
      "Processing batch 23: chunks 110 to 115\n",
      "✓ Processed batch 23\n",
      "Processing batch 24: chunks 115 to 120\n",
      "✓ Processed batch 24\n",
      "Processing batch 25: chunks 120 to 125\n",
      "✓ Processed batch 25\n",
      "Processing batch 26: chunks 125 to 130\n",
      "✓ Processed batch 26\n",
      "Processing batch 27: chunks 130 to 135\n",
      "✓ Processed batch 27\n",
      "Processing batch 28: chunks 135 to 140\n",
      "✓ Processed batch 28\n",
      "Processing batch 29: chunks 140 to 145\n",
      "✓ Processed batch 29\n",
      "Processing batch 30: chunks 145 to 150\n",
      "✓ Processed batch 30\n",
      "Processing batch 31: chunks 150 to 155\n",
      "✓ Processed batch 31\n",
      "Processing batch 32: chunks 155 to 160\n",
      "✓ Processed batch 32\n",
      "Processing batch 33: chunks 160 to 165\n",
      "✓ Processed batch 33\n",
      "Processing batch 34: chunks 165 to 170\n",
      "✓ Processed batch 34\n",
      "Processing batch 35: chunks 170 to 175\n",
      "✓ Processed batch 35\n",
      "Processing batch 36: chunks 175 to 180\n",
      "✓ Processed batch 36\n",
      "Processing batch 37: chunks 180 to 185\n",
      "✓ Processed batch 37\n",
      "Processing batch 38: chunks 185 to 190\n",
      "✓ Processed batch 38\n",
      "Processing batch 39: chunks 190 to 195\n",
      "✓ Processed batch 39\n",
      "Processing batch 40: chunks 195 to 200\n",
      "✓ Processed batch 40\n",
      "Processing batch 41: chunks 200 to 205\n",
      "✓ Processed batch 41\n",
      "Processing batch 42: chunks 205 to 210\n",
      "✓ Processed batch 42\n",
      "Processing batch 43: chunks 210 to 215\n",
      "✓ Processed batch 43\n",
      "Processing batch 44: chunks 215 to 220\n",
      "✓ Processed batch 44\n",
      "Processing batch 45: chunks 220 to 225\n",
      "✓ Processed batch 45\n",
      "Processing batch 46: chunks 225 to 230\n",
      "✓ Processed batch 46\n",
      "Processing batch 47: chunks 230 to 235\n",
      "✓ Processed batch 47\n",
      "Processing batch 48: chunks 235 to 240\n",
      "✓ Processed batch 48\n",
      "Processing batch 49: chunks 240 to 241\n",
      "✓ Processed batch 49\n",
      "✅ Vector store created successfully with all chunks\n",
      "✓ MMR Retriever initialized\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7d0e11da0a10>, search_type='mmr', search_kwargs={'k': 5})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import time\n",
    "# # Process chunks in smaller batches to avoid rate limits\n",
    "# batch_size = 5  # Adjust this based on your rate limits\n",
    "# all_embeddings = []\n",
    "\n",
    "# try:\n",
    "#     # Create vector store with first batch\n",
    "#     first_batch = chunks[:batch_size]\n",
    "#     print(f\"Processing first batch of {len(first_batch)} chunks...\")\n",
    "#     vectorstore = FAISS.from_documents(first_batch, embedding_model)\n",
    "    \n",
    "#     # Process remaining chunks in batches\n",
    "#     for i in range(batch_size, len(chunks), batch_size):\n",
    "#         batch = chunks[i:i+batch_size]\n",
    "#         print(f\"Processing batch {i//batch_size + 1}: chunks {i} to {min(i+batch_size, len(chunks))}\")\n",
    "        \n",
    "#         # Add delay between batches\n",
    "#         time.sleep(3)  # 3 second delay between batches\n",
    "        \n",
    "#         # Create temporary vector store for this batch\n",
    "#         temp_vectorstore = FAISS.from_documents(batch, embedding_model)\n",
    "        \n",
    "#         # Merge with main vector store\n",
    "#         vectorstore.merge_from(temp_vectorstore)\n",
    "        \n",
    "#         print(f\"✓ Processed batch {i//batch_size + 1}\")\n",
    "\n",
    "#     print(\"✅ Vector store created successfully with all chunks\")\n",
    "    \n",
    "#     ## step 3: MMR Retriever\n",
    "#     retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 5})\n",
    "#     print(\"✓ MMR Retriever initialized\")\n",
    "    \n",
    "# except Exception as e:\n",
    "#     print(f\"❌ Error creating vector store: {e}\")\n",
    "#     print(\"💡 Try reducing batch_size or increasing sleep time\")\n",
    "#     raise\n",
    "\n",
    "# retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc0d7dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='\\nYou are a helpful assistant. Expand the following query to improve document retrieval by adding relevant synonyms, technical terms, and useful context.\\n\\nOriginal query: \"{query}\"\\n\\nExpanded query:\\n')\n",
       "| ChatGoogleGenerativeAI(model='models/gemini-2.0-flash-exp', google_api_key=SecretStr('**********'), temperature=0.0, max_retries=2, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x7d0e11dcfda0>, default_metadata=())\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query expansion\n",
    "query_expansion_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a helpful assistant. Expand the following query to improve document retrieval by adding relevant synonyms, technical terms, and useful context.\n",
    "\n",
    "Original query: \"{query}\"\n",
    "\n",
    "Expanded query:\n",
    "\"\"\")\n",
    "\n",
    "query_expansion_chain=query_expansion_prompt| llm | StrOutputParser()\n",
    "query_expansion_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2ee030a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Okay, here\\'s an expanded query for \"Langchain memory,\" designed to improve document retrieval by incorporating synonyms, technical terms, and useful context:\\n\\n**Expanded Query:**\\n\\n**(Langchain OR \"Language Model Integration Framework\") AND (memory OR \"conversational memory\" OR \"chat history\" OR \"state management\" OR \"context management\" OR \"memory buffer\" OR \"knowledge graph\" OR \"vector database\" OR \"retrieval augmented generation\" OR \"RAG\") AND (persistence OR storage OR \"long-term memory\" OR \"short-term memory\" OR \"episodic memory\" OR \"semantic memory\" OR \"memory retrieval\" OR \"memory update\" OR \"memory deletion\" OR \"memory compression\" OR \"memory indexing\") AND (chains OR agents OR conversational OR chatbot OR \"dialogue system\" OR \"question answering\" OR \"task automation\") AND (implementation OR architecture OR design OR \"best practices\" OR tutorial OR example OR \"code snippet\" OR \"performance optimization\" OR limitations OR challenges OR evaluation OR comparison)**\\n\\n**Explanation of Additions and Rationale:**\\n\\n*   **Langchain OR \"Language Model Integration Framework\":**  Adds the full name of Langchain to ensure documents that use the full name are also retrieved.\\n\\n*   **(memory OR \"conversational memory\" OR \"chat history\" OR \"state management\" OR \"context management\" OR \"memory buffer\" OR \"knowledge graph\" OR \"vector database\" OR \"retrieval augmented generation\" OR \"RAG\"):** This section is crucial.  It expands \"memory\" to include:\\n    *   **\"conversational memory\" and \"chat history\":**  Common terms for storing past interactions.\\n    *   **\"state management\" and \"context management\":**  More general terms that encompass the idea of remembering information across interactions.\\n    *   **\"memory buffer\":** A common data structure used for storing memory.\\n    *   **\"knowledge graph\":** A structured way to represent and store information, often used for long-term memory.\\n    *   **\"vector database\":** A database that stores vector embeddings of text, allowing for semantic similarity search and retrieval, which is often used in conjunction with Langchain memory.\\n    *   **\"retrieval augmented generation\" OR \"RAG\":** A technique where a language model retrieves information from an external knowledge source (like a vector database) to improve its generation capabilities. This is a common use case for Langchain memory.\\n\\n*   **(persistence OR storage OR \"long-term memory\" OR \"short-term memory\" OR \"episodic memory\" OR \"semantic memory\" OR \"memory retrieval\" OR \"memory update\" OR \"memory deletion\" OR \"memory compression\" OR \"memory indexing\"):** This section focuses on how the memory is handled:\\n    *   **persistence OR storage:** Addresses how the memory is saved and retrieved.\\n    *   **\"long-term memory\" and \"short-term memory\":**  Distinguishes between different types of memory.\\n    *   **\"episodic memory\" and \"semantic memory\":** Further specifies types of long-term memory.\\n    *   **\"memory retrieval\", \"memory update\", \"memory deletion\", \"memory compression\", \"memory indexing\":**  These terms cover the operations performed on the memory.\\n\\n*   **(chains OR agents OR conversational OR chatbot OR \"dialogue system\" OR \"question answering\" OR \"task automation\"):**  Provides context for *how* the memory is being used within Langchain.  Langchain is often used to build chains of operations, agents that can interact with the world, and conversational applications.\\n    *   **\"dialogue system\":** A more formal term for a chatbot or conversational AI.\\n    *   **\"question answering\":** A common application of Langchain and memory.\\n    *   **\"task automation\":** Another application where memory can be useful.\\n\\n*   **(implementation OR architecture OR design OR \"best practices\" OR tutorial OR example OR \"code snippet\" OR \"performance optimization\" OR limitations OR challenges OR evaluation OR comparison):**  This section focuses on the *type* of information being sought.  Are you looking for how to implement it, the architecture, best practices, examples, limitations, or comparisons to other approaches?\\n\\n**How to Use This Expanded Query:**\\n\\n*   **Adapt to your specific needs:**  This is a broad query.  Remove terms that are not relevant to your specific search.  For example, if you are only interested in vector databases, remove the other memory types.\\n*   **Use Boolean operators (AND, OR, NOT):**  The query uses `OR` within each group and `AND` to connect the groups.  You can adjust these to refine your search.  For example, you could use `NOT` to exclude results that mention a specific limitation.\\n*   **Use quotes for exact phrases:**  The quotes around phrases like \"conversational memory\" ensure that the search engine looks for that exact phrase.\\n*   **Consider the search engine\\'s capabilities:**  Different search engines have different levels of support for complex queries.  You may need to simplify the query if you are using a less sophisticated search engine.\\n*   **Iterate and refine:**  Start with this expanded query and then refine it based on the results you get.  If you are getting too many irrelevant results, try adding more specific terms or using `NOT` to exclude unwanted terms.\\n\\nThis expanded query should significantly improve the relevance of your search results when looking for information about Langchain memory. Remember to tailor it to your specific needs and the capabilities of your search engine.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_expansion_chain.invoke({\"query\":\"Langchain memory\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f28bef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG answering prompt\n",
    "answer_prompt = PromptTemplate.from_template(\"\"\"\n",
    "Answer the question based on the context below.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {input}\n",
    "\"\"\")\n",
    "\n",
    "document_chain=create_stuff_documents_chain(llm=llm,prompt=answer_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32f5245a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Full RAG pipeline with query expansion\n",
    "rag_pipeline = (\n",
    "    RunnableMap({\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"context\": lambda x: retriever.invoke(query_expansion_chain.invoke({\"query\": x[\"input\"]}))\n",
    "    })\n",
    "    | document_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66638abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"input\": \"What types of memory does LangChain support?\",\n",
      "  \"expanded_query\": {\n",
      "    \"query\": \"What types of memory does LangChain support?  Specifically, what memory implementations, memory modules, memory classes, or memory components are available within the LangChain framework?  This includes, but is not limited to, conversation buffer memory, conversation buffer window memory, conversation summary memory, conversation summary buffer memory, vector store-backed memory, entity memory, knowledge graph memory, and context-aware memory.  Also, what are the different ways LangChain can store and retrieve conversational history, chat history, or previous interactions?  Are there specific data structures or databases used for memory storage, such as dictionaries, lists, Redis, Chroma, Pinecone, or other vector databases?  How does LangChain manage short-term memory and long-term memory?  What are the trade-offs between different memory types in terms of performance, cost, and context retention?  Are there any limitations or best practices for using specific memory types with LangChain?  Consider memory types suitable for both single-turn and multi-turn conversations, and for different LLMs (Large Language Models) integrated with LangChain.\",\n",
      "    \"synonyms\": [\n",
      "      \"memory implementations\",\n",
      "      \"memory modules\",\n",
      "      \"memory classes\",\n",
      "      \"memory components\",\n",
      "      \"conversational history\",\n",
      "      \"chat history\",\n",
      "      \"previous interactions\",\n",
      "      \"context retention\",\n",
      "      \"short-term memory\",\n",
      "      \"long-term memory\",\n",
      "      \"state management\",\n",
      "      \"conversation state\",\n",
      "      \"dialogue history\"\n",
      "    ],\n",
      "    \"technical_terms\": [\n",
      "      \"LangChain\",\n",
      "      \"LLM\",\n",
      "      \"Large Language Model\",\n",
      "      \"ConversationBufferMemory\",\n",
      "      \"ConversationBufferWindowMemory\",\n",
      "      \"ConversationSummaryMemory\",\n",
      "      \"ConversationSummaryBufferMemory\",\n",
      "      \"VectorStoreRetrieverMemory\",\n",
      "      \"EntityMemory\",\n",
      "      \"KnowledgeGraphMemory\",\n",
      "      \"ContextAwareMemory\",\n",
      "      \"Redis\",\n",
      "      \"Chroma\",\n",
      "      \"Pinecone\",\n",
      "      \"FAISS\",\n",
      "      \"Milvus\",\n",
      "      \"Weaviate\",\n",
      "      \"Vector Database\",\n",
      "      \"Embedding\",\n",
      "      \"Retrieval Augmented Generation (RAG)\"\n",
      "    ],\n",
      "    \"context\": [\n",
      "      \"LangChain is a framework for developing applications powered by language models.\",\n",
      "      \"Memory in LangChain refers to the ability to persist and retrieve information from previous interactions.\",\n",
      "      \"Different memory types offer different trade-offs in terms of performance, cost, and context retention.\",\n",
      "      \"Understanding the different memory types is crucial for building effective and robust LangChain applications.\",\n",
      "      \"Consider the specific requirements of your application when choosing a memory type.\"\n",
      "    ],\n",
      "    \"related_concepts\": [\n",
      "      \"Stateful applications\",\n",
      "      \"Stateless applications\",\n",
      "      \"Context window\",\n",
      "      \"Token limit\",\n",
      "      \"Prompt engineering\",\n",
      "      \"Retrieval Augmented Generation (RAG)\",\n",
      "      \"Knowledge base\"\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "Key improvements and explanations:\n",
      "\n",
      "* **Expanded Query:** The core query is significantly expanded to include more specific questions and related concepts.  This helps the search engine understand the user's intent more precisely.  It asks about specific memory types, storage mechanisms, and considerations like short-term vs. long-term memory.\n",
      "* **Synonyms:**  A list of synonyms is provided to cover different ways the user might phrase the same concept.  This is crucial for catching variations in terminology.\n",
      "* **Technical Terms:**  This section lists specific technical terms related to LangChain memory, including class names, database names, and relevant concepts.  This helps the search engine prioritize documents that use these terms.  It also includes common vector database options.\n",
      "* **Context:**  This section provides background information about LangChain and memory.  This helps the search engine understand the context of the query and prioritize relevant documents.  It explains the importance of memory in LangChain applications.\n",
      "* **Related Concepts:** This section lists related concepts that might be relevant to the user's query.  This helps the search engine find documents that cover these related topics.  This is useful for users who are exploring the broader landscape of LangChain and memory.\n",
      "* **Focus on Practical Considerations:** The expanded query includes questions about trade-offs, limitations, and best practices. This helps the user find practical information that they can use to build real-world applications.\n",
      "* **LLM Agnostic Consideration:** The query now considers memory types suitable for different LLMs, acknowledging that some memory types might be more appropriate for certain LLMs than others.\n",
      "* **RAG Integration:** The inclusion of \"Retrieval Augmented Generation (RAG)\" acknowledges that memory is often used in conjunction with RAG pipelines.\n",
      "\n",
      "This expanded query is much more likely to retrieve relevant and helpful documents than the original query.  It covers a wider range of topics, uses more specific terminology, and provides context to help the search engine understand the user's intent.\n",
      "✅ Answer:\n",
      " The provided context focuses on retrieval methods in LangChain, specifically hybrid retrieval and integration with vector databases. It does not mention the types of memory LangChain supports.\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Run query\n",
    "query = {\"input\": \"What types of memory does LangChain support?\"}\n",
    "print(query_expansion_chain.invoke({\"query\":query}))\n",
    "response = rag_pipeline.invoke(query)\n",
    "print(\"✅ Answer:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4b339b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rag_Course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
