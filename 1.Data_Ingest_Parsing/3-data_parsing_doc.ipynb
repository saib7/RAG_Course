{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe9f6034",
   "metadata": {},
   "source": [
    "# Word Document Processing with LangChain\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates different approaches to loading and processing Word (.docx) documents using LangChain's document loaders. We'll explore two main methods:\n",
    "\n",
    "1. **Docx2txtLoader** - Simple text extraction from Word documents\n",
    "2. **UnstructuredWordDocumentLoader** - Advanced parsing that preserves document structure and metadata\n",
    "\n",
    "## Prerequisites\n",
    "Before running this notebook, ensure you have the following packages installed:\n",
    "```bash\n",
    "uv add install langchain-community docx2txt python-docx unstructured\n",
    "```\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand different document loading strategies\n",
    "- Compare simple vs. structured document parsing\n",
    "- Learn how to handle metadata and document elements\n",
    "- Best practices for document preprocessing in RAG pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2424de32",
   "metadata": {},
   "source": [
    "### Word Document Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e243697",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Word Document Processing with LangChain Document Loaders\n",
    "\n",
    "This module demonstrates two different approaches for loading Word documents:\n",
    "1. Docx2txtLoader: Simple text extraction\n",
    "2. UnstructuredWordDocumentLoader: Advanced parsing with structure preservation\n",
    "\n",
    "Author: SAIB AHMED\n",
    "Date: 2024\n",
    "\"\"\"\n",
    "\n",
    "# Import necessary document loaders from LangChain Community\n",
    "from langchain_community.document_loaders import (\n",
    "    Docx2txtLoader,  # Simple text extraction from .docx files\n",
    "    UnstructuredWordDocumentLoader  # Advanced parsing with structure preservation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a9d643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1Ô∏è‚É£ Using Docx2txtLoader\n",
      "----------------------------------------\n",
      "‚úÖ Successfully loaded 1 document(s)\n",
      "üìÑ Document type: Word Document (.docx)\n",
      "üìù Content preview (first 200 chars): Project Proposal: RAG Implementation\n",
      "\n",
      "Executive Summary\n",
      "\n",
      "This proposal outlines the implementation of a Retrieval-Augmented Generation system for our organization.\n",
      "\n",
      "Objectives\n",
      "\n",
      "Key objectives include:...\n",
      "üè∑Ô∏è  Document metadata: {'source': 'data/word_files/proposal.docx'}\n"
     ]
    }
   ],
   "source": [
    "# Method 1: Using Docx2txtLoader\n",
    "# ==================================\n",
    "# Docx2txtLoader provides simple text extraction from Word documents\n",
    "# Pros: Fast, lightweight, simple to use\n",
    "# Cons: Loses document structure and formatting information\n",
    "\n",
    "print(\"1Ô∏è‚É£ Using Docx2txtLoader\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "try:pip \n",
    "    # Initialize the Docx2txtLoader with the path to your Word document\n",
    "    docx_loader = Docx2txtLoader(\"data/word_files/proposal.docx\")\n",
    "    \n",
    "    # Load the document - returns a list of Document objects\n",
    "    docs = docx_loader.load()\n",
    "    \n",
    "    # Display basic information about the loaded document\n",
    "    print(f\"‚úÖ Successfully loaded {len(docs)} document(s)\")\n",
    "    print(f\"üìÑ Document type: Word Document (.docx)\")\n",
    "    print(f\"üìù Content preview (first 200 chars): {docs[0].page_content[:200]}...\")\n",
    "    print(f\"üè∑Ô∏è  Document metadata: {docs[0].metadata}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Error: The specified file was not found. Please check the file path.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading document: {e}\")\n",
    "    print(\"üí° Tip: Make sure 'docx2txt' package is installed: pip install docx2txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "768eecd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2Ô∏è‚É£ Using UnstructuredWordDocumentLoader\n",
      "--------------------------------------------------\n",
      "‚úÖ Successfully loaded 20 document elements\n",
      "\n",
      "Element 1:\n",
      "  üìã Type: Title\n",
      "  üìù Content preview: Project Proposal: RAG Implementation...\n",
      "  üè∑Ô∏è  Metadata keys: ['source', 'category_depth', 'file_directory', 'filename', 'last_modified', 'languages', 'filetype', 'category', 'element_id']\n",
      "\n",
      "Element 2:\n",
      "  üìã Type: Title\n",
      "  üìù Content preview: Executive Summary...\n",
      "  üè∑Ô∏è  Metadata keys: ['source', 'category_depth', 'file_directory', 'filename', 'last_modified', 'languages', 'filetype', 'category', 'element_id']\n",
      "\n",
      "Element 3:\n",
      "  üìã Type: NarrativeText\n",
      "  üìù Content preview: This proposal outlines the implementation of a Retrieval-Augmented Generation system for our organiz...\n",
      "  üè∑Ô∏è  Metadata keys: ['source', 'category_depth', 'file_directory', 'filename', 'last_modified', 'languages', 'filetype', 'parent_id', 'category', 'element_id']\n"
     ]
    }
   ],
   "source": [
    "# Method 2: Using UnstructuredWordDocumentLoader\n",
    "# ================================================\n",
    "# UnstructuredWordDocumentLoader provides advanced parsing capabilities\n",
    "# Pros: Preserves document structure, extracts metadata, handles various elements\n",
    "# Cons: Slower processing, requires additional dependencies\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ Using UnstructuredWordDocumentLoader\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "try:\n",
    "    # Initialize UnstructuredWordDocumentLoader with mode=\"elements\"\n",
    "    # mode=\"elements\" returns each document element as a separate Document object\n",
    "    unstructured_loader = UnstructuredWordDocumentLoader(\n",
    "        \"data/word_files/proposal.docx\", \n",
    "        mode=\"elements\"\n",
    "    )\n",
    "    \n",
    "    # Load the document and extract all elements\n",
    "    unstructured_docs = unstructured_loader.load()\n",
    "    \n",
    "    # Display summary information about the loaded elements\n",
    "    print(f\"‚úÖ Successfully loaded {len(unstructured_docs)} document elements\")\n",
    "    \n",
    "    # Show details for the first 3 elements to understand the structure\n",
    "    for i, doc in enumerate(unstructured_docs[:3]):\n",
    "        print(f\"\\nElement {i+1}:\")\n",
    "        print(f\"  üìã Type: {doc.metadata.get('category', 'unknown')}\")\n",
    "        print(f\"  üìù Content preview: {doc.page_content[:100]}...\")\n",
    "        \n",
    "        # Show additional metadata if available\n",
    "        if len(doc.metadata) > 1:\n",
    "            print(f\"  üè∑Ô∏è  Metadata keys: {list(doc.metadata.keys())}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Error: The specified file was not found. Please check the file path.\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import Error: {e}\")\n",
    "    print(\"üí° Tip: Make sure required packages are installed:\")\n",
    "    print(\"   pip install python-docx unstructured\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Unexpected error: {e}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f2db123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/word_files/proposal.docx', 'category_depth': 0, 'file_directory': 'data/word_files', 'filename': 'proposal.docx', 'last_modified': '2025-09-12T11:09:23', 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'category': 'Title', 'element_id': 'bb0410bfd160ef866f8d4357b0949db2'}, page_content='Project Proposal: RAG Implementation'),\n",
       " Document(metadata={'source': 'data/word_files/proposal.docx', 'category_depth': 0, 'file_directory': 'data/word_files', 'filename': 'proposal.docx', 'last_modified': '2025-09-12T11:09:23', 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'category': 'Title', 'element_id': 'c0f844859abf08d9506856b3aed4a719'}, page_content='Executive Summary'),\n",
       " Document(metadata={'source': 'data/word_files/proposal.docx', 'category_depth': 0, 'file_directory': 'data/word_files', 'filename': 'proposal.docx', 'last_modified': '2025-09-12T11:09:23', 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'parent_id': 'c0f844859abf08d9506856b3aed4a719', 'category': 'NarrativeText', 'element_id': 'bbc04fc71e33a92df30d7fe7c33b6375'}, page_content='This proposal outlines the implementation of a Retrieval-Augmented Generation system for our organization.'),\n",
       " Document(metadata={'source': 'data/word_files/proposal.docx', 'category_depth': 0, 'file_directory': 'data/word_files', 'filename': 'proposal.docx', 'last_modified': '2025-09-12T11:09:23', 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'category': 'Title', 'element_id': 'a2c8ca6c90e23196fcf4be625007bbd6'}, page_content='Objectives'),\n",
       " Document(metadata={'source': 'data/word_files/proposal.docx', 'category_depth': 0, 'file_directory': 'data/word_files', 'filename': 'proposal.docx', 'last_modified': '2025-09-12T11:09:23', 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'parent_id': 'a2c8ca6c90e23196fcf4be625007bbd6', 'category': 'NarrativeText', 'element_id': '335654d234a93f0eb1e1e6798c633eb7'}, page_content='Key objectives include:'),\n",
       " Document(metadata={'source': 'data/word_files/proposal.docx', 'category_depth': 0, 'file_directory': 'data/word_files', 'filename': 'proposal.docx', 'last_modified': '2025-09-12T11:09:23', 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'parent_id': 'a2c8ca6c90e23196fcf4be625007bbd6', 'category': 'ListItem', 'element_id': 'a62787f7e487c3715929cc34a512d2df'}, page_content='Improve information retrieval accuracy'),\n",
       " Document(metadata={'source': 'data/word_files/proposal.docx', 'category_depth': 0, 'file_directory': 'data/word_files', 'filename': 'proposal.docx', 'last_modified': '2025-09-12T11:09:23', 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'parent_id': 'a2c8ca6c90e23196fcf4be625007bbd6', 'category': 'ListItem', 'element_id': '7403c111f034d07762a2ea3f9e77fd55'}, page_content='Reduce response time for customer queries'),\n",
       " Document(metadata={'source': 'data/word_files/proposal.docx', 'category_depth': 0, 'file_directory': 'data/word_files', 'filename': 'proposal.docx', 'last_modified': '2025-09-12T11:09:23', 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'parent_id': 'a2c8ca6c90e23196fcf4be625007bbd6', 'category': 'ListItem', 'element_id': 'b7a32dbf801712e0cbb4301b40fc1332'}, page_content='Integrate with existing knowledge base'),\n",
       " Document(metadata={'source': 'data/word_files/proposal.docx', 'category_depth': 0, 'file_directory': 'data/word_files', 'filename': 'proposal.docx', 'last_modified': '2025-09-12T11:09:23', 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'category': 'Title', 'element_id': '03384feebdc9dbc6c3e66f42a31ae4d4'}, page_content='Budget and Timeline'),\n",
       " Document(metadata={'source': 'data/word_files/proposal.docx', 'category_depth': 0, 'file_directory': 'data/word_files', 'filename': 'proposal.docx', 'last_modified': '2025-09-12T11:09:23', 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'parent_id': '03384feebdc9dbc6c3e66f42a31ae4d4', 'category': 'UncategorizedText', 'element_id': '2b656c76dce795af739297289ec70cb4'}, page_content='Budget: $50,000'),\n",
       " Document(metadata={'source': 'data/word_files/proposal.docx', 'category_depth': 0, 'file_directory': 'data/word_files', 'filename': 'proposal.docx', 'last_modified': '2025-09-12T11:09:23', 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'parent_id': '03384feebdc9dbc6c3e66f42a31ae4d4', 'category': 'UncategorizedText', 'element_id': '579456f56ae28a18e9113d256cf0c677'}, page_content='Timeline: 3 months'),\n",
       " Document(metadata={'source': 'data/word_files/proposal.docx', 'category_depth': 0, 'file_directory': 'data/word_files', 'filename': 'proposal.docx', 'last_modified': '2025-09-12T11:09:23', 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'parent_id': '03384feebdc9dbc6c3e66f42a31ae4d4', 'category': 'UncategorizedText', 'element_id': 'cd21a830803498d697e79322b08cb621'}, page_content='Team: 4 developers, 1 project manager'),\n",
       " Document(metadata={'source': 'data/word_files/proposal.docx', 'category_depth': 0, 'file_directory': 'data/word_files', 'filename': 'proposal.docx', 'last_modified': '2025-09-12T11:09:23', 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'category': 'Title', 'element_id': '79f776a9342d2b31ac42ee74e884601d'}, page_content='Technical Requirements'),\n",
       " Document(metadata={'source': 'data/word_files/proposal.docx', 'category_depth': 0, 'file_directory': 'data/word_files', 'filename': 'proposal.docx', 'last_modified': '2025-09-12T11:09:23', 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'parent_id': '79f776a9342d2b31ac42ee74e884601d', 'category': 'NarrativeText', 'element_id': 'bd3ed1f0473cc4dc2a91175293045731'}, page_content='Required technologies:'),\n",
       " Document(metadata={'source': 'data/word_files/proposal.docx', 'category_depth': 0, 'file_directory': 'data/word_files', 'filename': 'proposal.docx', 'last_modified': '2025-09-12T11:09:23', 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'parent_id': '79f776a9342d2b31ac42ee74e884601d', 'category': 'ListItem', 'element_id': 'bd3174066f748a60216ee2b8fec3e3c9'}, page_content='Python 3.8+'),\n",
       " Document(metadata={'source': 'data/word_files/proposal.docx', 'category_depth': 0, 'file_directory': 'data/word_files', 'filename': 'proposal.docx', 'last_modified': '2025-09-12T11:09:23', 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'parent_id': '79f776a9342d2b31ac42ee74e884601d', 'category': 'ListItem', 'element_id': 'e9c9cf7f0ab0b8741759b94fde3ca1ec'}, page_content='OpenAI API access'),\n",
       " Document(metadata={'source': 'data/word_files/proposal.docx', 'category_depth': 0, 'file_directory': 'data/word_files', 'filename': 'proposal.docx', 'last_modified': '2025-09-12T11:09:23', 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'parent_id': '79f776a9342d2b31ac42ee74e884601d', 'category': 'ListItem', 'element_id': 'c7afb3a7eb2cda7dfb6b6ca21f84a62c'}, page_content='Vector database (ChromaDB)'),\n",
       " Document(metadata={'source': 'data/word_files/proposal.docx', 'category_depth': 0, 'file_directory': 'data/word_files', 'filename': 'proposal.docx', 'last_modified': '2025-09-12T11:09:23', 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'parent_id': '79f776a9342d2b31ac42ee74e884601d', 'category': 'ListItem', 'element_id': 'a5c92389ea9457df2863111aa3643e9f'}, page_content='16GB RAM minimum'),\n",
       " Document(metadata={'source': 'data/word_files/proposal.docx', 'category_depth': 0, 'file_directory': 'data/word_files', 'filename': 'proposal.docx', 'last_modified': '2025-09-12T11:09:23', 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'category': 'Title', 'element_id': '7da2807bf22f20a489b6af8e62840a5a'}, page_content='Project Phases'),\n",
       " Document(metadata={'source': 'data/word_files/proposal.docx', 'file_directory': 'data/word_files', 'filename': 'proposal.docx', 'last_modified': '2025-09-12T11:09:23', 'text_as_html': '<table><tr><td>Phase</td><td>Duration</td><td>Deliverables</td></tr><tr><td>Research</td><td>2 weeks</td><td>Technology evaluation report</td></tr><tr><td>Development</td><td>8 weeks</td><td>Working RAG prototype</td></tr><tr><td>Testing</td><td>2 weeks</td><td>Performance benchmarks</td></tr></table>', 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'parent_id': '7da2807bf22f20a489b6af8e62840a5a', 'category': 'Table', 'element_id': 'e551119ba54073b0c9a4ac4d95ac929f'}, page_content='Phase Duration Deliverables Research 2 weeks Technology evaluation report Development 8 weeks Working RAG prototype Testing 2 weeks Performance benchmarks')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the unstructured documents in detail\n",
    "# This will display all the parsed elements from the Word document\n",
    "# Each element represents a different part of the document (paragraphs, titles, etc.)\n",
    "unstructured_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "985d0b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Document Loading Methods Comparison\n",
      "==================================================\n",
      "Docx2txtLoader results:\n",
      "  ‚Ä¢ Number of documents: 1\n",
      "  ‚Ä¢ Content length: 743 characters\n",
      "  ‚Ä¢ Metadata keys: ['source']\n",
      "\n",
      "UnstructuredWordDocumentLoader results:\n",
      "  ‚Ä¢ Number of elements: 20\n",
      "  ‚Ä¢ Total content length: 680 characters\n",
      "  ‚Ä¢ Element types: {'NarrativeText', 'UncategorizedText', 'Table', 'ListItem', 'Title'}\n",
      "\n",
      "üí° Key Insights:\n",
      "  ‚Ä¢ Structured parsing found 20 separate elements\n",
      "  ‚Ä¢ Simple parsing treats the entire document as one unit\n",
      "  ‚Ä¢ Structured parsing preserves document hierarchy and element types\n",
      "\n",
      "üéØ When to use each method:\n",
      "  üìù Docx2txtLoader:\n",
      "     - Quick text extraction for search or basic analysis\n",
      "     - When document structure is not important\n",
      "     - For simple RAG applications with minimal preprocessing\n",
      "  üèóÔ∏è  UnstructuredWordDocumentLoader:\n",
      "     - When document structure matters (headings, paragraphs, etc.)\n",
      "     - For advanced RAG systems that need element-level processing\n",
      "     - When you need metadata about document elements\n"
     ]
    }
   ],
   "source": [
    "# Comparison and Analysis\n",
    "# ========================\n",
    "\"\"\"\n",
    "This section compares the two document loading methods and analyzes their outputs.\n",
    "It helps you understand when to use each approach based on your specific requirements.\n",
    "\"\"\"\n",
    "\n",
    "print(\"üìä Document Loading Methods Comparison\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Compare basic statistics between the two methods\n",
    "if 'docs' in locals() and 'unstructured_docs' in locals():\n",
    "    print(f\"Docx2txtLoader results:\")\n",
    "    print(f\"  ‚Ä¢ Number of documents: {len(docs)}\")\n",
    "    print(f\"  ‚Ä¢ Content length: {len(docs[0].page_content) if docs else 0} characters\")\n",
    "    print(f\"  ‚Ä¢ Metadata keys: {list(docs[0].metadata.keys()) if docs else []}\")\n",
    "    \n",
    "    print(f\"\\nUnstructuredWordDocumentLoader results:\")\n",
    "    print(f\"  ‚Ä¢ Number of elements: {len(unstructured_docs)}\")\n",
    "    print(f\"  ‚Ä¢ Total content length: {sum(len(doc.page_content) for doc in unstructured_docs)} characters\")\n",
    "    print(f\"  ‚Ä¢ Element types: {set(doc.metadata.get('category', 'unknown') for doc in unstructured_docs)}\")\n",
    "    \n",
    "    print(f\"\\nüí° Key Insights:\")\n",
    "    print(f\"  ‚Ä¢ Structured parsing found {len(unstructured_docs)} separate elements\")\n",
    "    print(f\"  ‚Ä¢ Simple parsing treats the entire document as one unit\")\n",
    "    print(f\"  ‚Ä¢ Structured parsing preserves document hierarchy and element types\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Run the previous cells first to compare the methods\")\n",
    "\n",
    "print(f\"\\nüéØ When to use each method:\")\n",
    "print(f\"  üìù Docx2txtLoader:\")\n",
    "print(f\"     - Quick text extraction for search or basic analysis\")\n",
    "print(f\"     - When document structure is not important\")\n",
    "print(f\"     - For simple RAG applications with minimal preprocessing\")\n",
    "print(f\"  üèóÔ∏è  UnstructuredWordDocumentLoader:\")\n",
    "print(f\"     - When document structure matters (headings, paragraphs, etc.)\")\n",
    "print(f\"     - For advanced RAG systems that need element-level processing\")\n",
    "print(f\"     - When you need metadata about document elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387df428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° Performance Analysis\n",
      "=========================\n",
      "üìä Memory Usage:\n",
      "  ‚Ä¢ Docx2txtLoader: 0 bytes\n",
      "  ‚Ä¢ UnstructuredLoader: 0 bytes\n",
      "\n",
      "üîç Document Granularity:\n",
      "  ‚Ä¢ Simple loader: 0 document(s)\n",
      "  ‚Ä¢ Structured loader: 0 element(s)\n",
      "\n",
      "üí° Recommendations:\n",
      "  ‚Ä¢ For large documents: Use Docx2txtLoader for faster processing\n",
      "  ‚Ä¢ For structured analysis: Use UnstructuredWordDocumentLoader\n",
      "  ‚Ä¢ For production RAG: Consider document chunking strategies\n"
     ]
    }
   ],
   "source": [
    "# Performance and Memory Considerations\n",
    "# ======================================\n",
    "\"\"\"\n",
    "This section analyzes the performance and memory usage of both methods.\n",
    "Understanding these aspects is crucial for production RAG applications.\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import time\n",
    "\n",
    "def analyze_document_loader_performance():\n",
    "    \"\"\"\n",
    "    Analyzes and compares the performance characteristics of both document loaders.\n",
    "    pip \n",
    "    Returns:\n",
    "        dict: Performance metrics for both loaders\n",
    "    \"\"\"\n",
    "    performance_metrics = {}\n",
    "    \n",
    "    # Test Docx2txtLoader performance\n",
    "    if 'docs' in locals():\n",
    "        performance_metrics['docx2txt'] = {\n",
    "            'memory_usage': sys.getsizeof(docs),\n",
    "            'document_count': len(docs),\n",
    "            'avg_doc_size': len(docs[0].page_content) if docs else 0\n",
    "        }\n",
    "    \n",
    "    # Test UnstructuredWordDocumentLoader performance  \n",
    "    if 'unstructured_docs' in locals():\n",
    "        total_memory = sum(sys.getsizeof(doc.page_content) for doc in unstructured_docs)\n",
    "        performance_metrics['unstructured'] = {\n",
    "            'memory_usage': total_memory,\n",
    "            'element_count': len(unstructured_docs),\n",
    "            'avg_element_size': total_memory / len(unstructured_docs) if unstructured_docs else 0\n",
    "        }\n",
    "    \n",
    "    return performance_metrics\n",
    "\n",
    "# Analyze performance if both methods have been executed\n",
    "if 'docs' in locals() and 'unstructured_docs' in locals():\n",
    "    metrics = analyze_document_loader_performance()\n",
    "    \n",
    "    print(\"‚ö° Performance Analysis\")\n",
    "    print(\"=\" * 25)\n",
    "    \n",
    "    print(f\"üìä Memory Usage:\")\n",
    "    print(f\"  ‚Ä¢ Docx2txtLoader: {metrics.get('docx2txt', {}).get('memory_usage', 0)} bytes\")\n",
    "    print(f\"  ‚Ä¢ UnstructuredLoader: {metrics.get('unstructured', {}).get('memory_usage', 0)} bytes\")\n",
    "    \n",
    "    print(f\"\\nüîç Document Granularity:\")\n",
    "    print(f\"  ‚Ä¢ Simple loader: {metrics.get('docx2txt', {}).get('document_count', 0)} document(s)\")\n",
    "    print(f\"  ‚Ä¢ Structured loader: {metrics.get('unstructured', {}).get('element_count', 0)} element(s)\")\n",
    "    \n",
    "    print(f\"\\nüí° Recommendations:\")\n",
    "    print(f\"  ‚Ä¢ For large documents: Use Docx2txtLoader for faster processing\")\n",
    "    print(f\"  ‚Ä¢ For structured analysis: Use UnstructuredWordDocumentLoader\")\n",
    "    print(f\"  ‚Ä¢ For production RAG: Consider document chunking strategies\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Run the document loading cells first to see performance analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb99958",
   "metadata": {},
   "source": [
    "## Best Practices and Troubleshooting\n",
    "\n",
    "### Common Issues and Solutions\n",
    "\n",
    "1. **Module Import Errors**\n",
    "   - `ModuleNotFoundError: No module named 'docx2txt'` ‚Üí Install with `pip install docx2txt`\n",
    "   - `ModuleNotFoundError: No module named 'docx'` ‚Üí Install with `pip install python-docx`\n",
    "   - `ModuleNotFoundError: No module named 'unstructured'` ‚Üí Install with `pip install unstructured`\n",
    "\n",
    "2. **File Path Issues**\n",
    "   - Use absolute paths or ensure relative paths are correct\n",
    "   - Check file permissions and accessibility\n",
    "   - Verify the file exists and is a valid .docx format\n",
    "\n",
    "3. **Performance Considerations**\n",
    "   - For large documents (>10MB): Consider using Docx2txtLoader for speed\n",
    "   - For structured analysis: UnstructuredWordDocumentLoader is worth the extra processing time\n",
    "   - Implement chunking strategies for very large documents\n",
    "\n",
    "### Production RAG Pipeline Recommendations\n",
    "\n",
    "- **Document Preprocessing**: Always validate document format before processing\n",
    "- **Error Handling**: Implement robust exception handling for file operations\n",
    "- **Chunking Strategy**: Split large documents into manageable chunks (500-1000 tokens)\n",
    "- **Metadata Preservation**: Use UnstructuredWordDocumentLoader when structure matters\n",
    "- **Monitoring**: Track processing time and memory usage in production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e51b4566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Document Processing Utilities\n",
      "===================================\n",
      "üí° Use these utility functions in your RAG pipeline:\n",
      "  ‚Ä¢ load_document_safe() - Safe document loading with error handling\n",
      "  ‚Ä¢ analyze_document_structure() - Analyze document structure and metadata\n",
      "\n",
      "Example usage:\n",
      "  docs, success, error = load_document_safe('your_file.docx', 'unstructured')\n",
      "  if success:\n",
      "      analysis = analyze_document_structure(docs)\n",
      "      print(f'Found {analysis[\"total_documents\"]} elements')\n"
     ]
    }
   ],
   "source": [
    "# Utility Functions for Document Processing\n",
    "# ==========================================\n",
    "\"\"\"\n",
    "This section provides utility functions for document processing that can be reused \n",
    "in production RAG applications.\n",
    "\"\"\"\n",
    "\n",
    "def load_document_safe(file_path: str, method: str = \"docx2txt\"):\n",
    "    \"\"\"\n",
    "    Safely load a Word document using the specified method.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the Word document\n",
    "        method (str): Loading method - either \"docx2txt\" or \"unstructured\"\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (documents_list, success_flag, error_message)\n",
    "    \n",
    "    Example:\n",
    "        docs, success, error = load_document_safe(\"proposal.docx\", \"unstructured\")\n",
    "        if success:\n",
    "            print(f\"Loaded {len(docs)} document elements\")\n",
    "        else:\n",
    "            print(f\"Error: {error}\")\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if method == \"docx2txt\":\n",
    "            loader = Docx2txtLoader(file_path)\n",
    "        elif method == \"unstructured\":\n",
    "            loader = UnstructuredWordDocumentLoader(file_path, mode=\"elements\")\n",
    "        else:\n",
    "            return None, False, f\"Unsupported method: {method}\"\n",
    "        \n",
    "        documents = loader.load()\n",
    "        return documents, True, None\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        return None, False, f\"File not found: {file_path}\"\n",
    "    except ImportError as e:\n",
    "        return None, False, f\"Missing dependency: {e}\"\n",
    "    except Exception as e:\n",
    "        return None, False, f\"Unexpected error: {e}\"\n",
    "\n",
    "def analyze_document_structure(documents: list):\n",
    "    \"\"\"\n",
    "    Analyze the structure of loaded documents.\n",
    "    \n",
    "    Args:\n",
    "        documents (list): List of Document objects\n",
    "    \n",
    "    Returns:\n",
    "        dict: Analysis results including statistics and structure info\n",
    "    \"\"\"\n",
    "    if not documents:\n",
    "        return {\"error\": \"No documents provided\"}\n",
    "    \n",
    "    analysis = {\n",
    "        \"total_documents\": len(documents),\n",
    "        \"total_content_length\": sum(len(doc.page_content) for doc in documents),\n",
    "        \"avg_content_length\": sum(len(doc.page_content) for doc in documents) / len(documents),\n",
    "        \"metadata_keys\": set(),\n",
    "        \"element_types\": set()\n",
    "    }\n",
    "    \n",
    "    # Analyze metadata and element types\n",
    "    for doc in documents:\n",
    "        analysis[\"metadata_keys\"].update(doc.metadata.keys())\n",
    "        if \"category\" in doc.metadata:\n",
    "            analysis[\"element_types\"].add(doc.metadata[\"category\"])\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "# Example usage of utility functions\n",
    "print(\"üîß Document Processing Utilities\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# You can test these functions with your documents\n",
    "print(\"üí° Use these utility functions in your RAG pipeline:\")\n",
    "print(\"  ‚Ä¢ load_document_safe() - Safe document loading with error handling\")\n",
    "print(\"  ‚Ä¢ analyze_document_structure() - Analyze document structure and metadata\")\n",
    "print(\"\\nExample usage:\")\n",
    "print(\"  docs, success, error = load_document_safe('your_file.docx', 'unstructured')\")\n",
    "print(\"  if success:\")\n",
    "print(\"      analysis = analyze_document_structure(docs)\")\n",
    "print(\"      print(f'Found {analysis[\\\"total_documents\\\"]} elements')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296feafe",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "In this notebook, we explored two different approaches for processing Word documents:\n",
    "\n",
    "1. **Docx2txtLoader**: Simple, fast text extraction ideal for basic RAG applications\n",
    "2. **UnstructuredWordDocumentLoader**: Advanced parsing that preserves document structure and metadata\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- **Choose the right tool**: Use Docx2txtLoader for speed, UnstructuredWordDocumentLoader for structure\n",
    "- **Error handling is crucial**: Always implement proper exception handling for file operations\n",
    "- **Consider performance**: Memory usage and processing time scale differently between methods\n",
    "- **Structure matters**: Structured parsing enables more sophisticated document analysis\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Experiment with your own documents**: Try both methods with different document types\n",
    "2. **Implement chunking strategies**: Split large documents for better processing\n",
    "3. **Build a document pipeline**: Combine these techniques with text embedding and retrieval\n",
    "4. **Optimize for production**: Consider caching, parallel processing, and monitoring\n",
    "\n",
    "### Resources for Further Learning\n",
    "\n",
    "- [LangChain Document Loaders](https://python.langchain.com/docs/modules/data_connection/document_loaders/)\n",
    "- [Unstructured Library Documentation](https://docs.unstructured.io/)\n",
    "- [RAG Pipeline Best Practices](https://docs.llamaindex.ai/en/stable/optimizing/building_rag.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07200a92",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rag_Course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
