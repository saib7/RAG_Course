{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4028d04d",
   "metadata": {},
   "source": [
    "# Pinecone Vector Database Integration\n",
    "\n",
    "This notebook demonstrates how to use Pinecone as a vector database for storing and retrieving document embeddings in a RAG (Retrieval-Augmented Generation) system.\n",
    "\n",
    "## Overview\n",
    "- Set up Pinecone vector database\n",
    "- Create embeddings using Google's Gemini model\n",
    "- Store documents with metadata\n",
    "- Perform similarity searches with filtering\n",
    "- Use retrievers for advanced querying\n",
    "\n",
    "## Prerequisites\n",
    "- Pinecone API key\n",
    "- Google API key\n",
    "- Required packages: pinecone-client, langchain-pinecone, langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1e6cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ API keys loaded successfully\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Environment Setup and API Key Configuration\n",
    "\n",
    "This cell loads the required API keys from environment variables and validates\n",
    "that all necessary credentials are available for the Pinecone and Google services.\n",
    "\"\"\"\n",
    "\n",
    "# Load environment variables\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get API keys from environment\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
    "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "# Validate that required API keys are loaded\n",
    "if not PINECONE_API_KEY:\n",
    "    raise ValueError(\"PINECONE_API_KEY not found in environment variables\")\n",
    "if not GOOGLE_API_KEY:\n",
    "    raise ValueError(\"GOOGLE_API_KEY not found in environment variables\")\n",
    "\n",
    "print(\"âœ“ API keys loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b82c24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Initialize Pinecone Client\n",
    "\n",
    "Create a connection to Pinecone using the API key.\n",
    "Pinecone is a vector database service that allows for efficient similarity search\n",
    "and retrieval of high-dimensional vectors.\n",
    "\"\"\"\n",
    "\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# Initialize Pinecone client with API key\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "print(\"âœ“ Pinecone client initialized successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f94585",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bjit/Desktop/Storage01/SelfDevelopment/Rag_Course/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Initialize Google Generative AI Embeddings\n",
    "\n",
    "Set up the embedding model using Google's Gemini embedding model.\n",
    "This model converts text into high-dimensional vectors (embeddings) that\n",
    "capture semantic meaning and can be used for similarity comparisons.\n",
    "\"\"\"\n",
    "\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "\n",
    "# Initialize Google Gemini embeddings model\n",
    "# The gemini-embedding-001 model produces 3072-dimensional vectors\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")\n",
    "print(\"âœ“ Google Gemini embeddings model initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160e4e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create and Configure Pinecone Index\n",
    "\n",
    "This cell creates a new Pinecone index if it doesn't exist, or connects to an existing one.\n",
    "The index is configured with:\n",
    "- Dimension: 3072 (matching the Gemini embedding model output)\n",
    "- Metric: cosine similarity for comparing vectors\n",
    "- Serverless specification for automatic scaling\n",
    "\"\"\"\n",
    "\n",
    "from pinecone import ServerlessSpec\n",
    "\n",
    "# Define index configuration\n",
    "index_name = \"rag\"  # Name of the Pinecone index\n",
    "dimension = 3072   # Must match the embedding model's output dimension\n",
    "metric = \"cosine\"  # Similarity metric for vector comparisons\n",
    "\n",
    "# Create index if it doesn't exist\n",
    "if not pc.has_index(index_name):\n",
    "    print(f\"Creating new index '{index_name}'...\")\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=dimension,\n",
    "        metric=metric,\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",           # Cloud provider\n",
    "            region=\"us-east-1\"     # AWS region\n",
    "        ),\n",
    "    )\n",
    "    print(f\"âœ“ Index '{index_name}' created successfully\")\n",
    "else:\n",
    "    print(f\"âœ“ Index '{index_name}' already exists\")\n",
    "\n",
    "# Connect to the index\n",
    "index = pc.Index(index_name)\n",
    "print(f\"âœ“ Connected to index: {index_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8625b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pinecone.db_data.index.Index at 0x71fe226f6e10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Display Index Information\n",
    "\n",
    "Show the current state and configuration of the Pinecone index.\n",
    "\"\"\"\n",
    "print(\"Index Information:\")\n",
    "print(f\"Index: {index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55be0d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bjit/Desktop/Storage01/SelfDevelopment/Rag_Course/.venv/lib/python3.12/site-packages/langchain_pinecone/__init__.py:3: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain_pinecone.vectorstores import Pinecone, PineconeVectorStore\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Initialize LangChain Pinecone Vector Store\n",
    "\n",
    "Create a LangChain wrapper around the Pinecone index that provides\n",
    "a unified interface for document storage and retrieval operations.\n",
    "This abstraction makes it easier to work with vectors in LangChain applications.\n",
    "\"\"\"\n",
    "\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "# Create vector store wrapper\n",
    "vector_store = PineconeVectorStore(\n",
    "    index=index,           # The Pinecone index instance\n",
    "    embedding=embeddings   # The embedding function to use\n",
    ")\n",
    "print(\"âœ“ LangChain Pinecone vector store initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ef3833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x71fe20220ce0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Display Vector Store Information\n",
    "\"\"\"\n",
    "print(\"Vector Store Information:\")\n",
    "print(f\"Vector Store: {vector_store}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863ea745",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create Sample Documents\n",
    "\n",
    "Define a collection of sample documents with different content types and sources.\n",
    "Each document includes:\n",
    "- page_content: The actual text content\n",
    "- metadata: Additional information like source type for filtering\n",
    "\n",
    "These documents simulate different types of content you might encounter in a RAG system:\n",
    "- Social media posts (tweets)\n",
    "- News articles\n",
    "- Website content\n",
    "\"\"\"\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Personal/Social Media Content\n",
    "document_1 = Document(\n",
    "    page_content=\"I had chocolate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "    metadata={\"source\": \"tweet\", \"category\": \"personal\"},\n",
    ")\n",
    "\n",
    "document_2 = Document(\n",
    "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
    "    metadata={\"source\": \"tweet\", \"category\": \"entertainment\"},\n",
    ")\n",
    "\n",
    "document_3 = Document(\n",
    "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
    "    metadata={\"source\": \"tweet\", \"category\": \"technology\"},\n",
    ")\n",
    "\n",
    "document_8 = Document(\n",
    "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
    "    metadata={\"source\": \"tweet\", \"category\": \"technology\"},\n",
    ")\n",
    "\n",
    "document_10 = Document(\n",
    "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
    "    metadata={\"source\": \"tweet\", \"category\": \"personal\"},\n",
    ")\n",
    "\n",
    "# News Content\n",
    "document_2 = Document(\n",
    "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "    metadata={\"source\": \"news\", \"category\": \"weather\"},\n",
    ")\n",
    "\n",
    "document_4 = Document(\n",
    "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
    "    metadata={\"source\": \"news\", \"category\": \"crime\"},\n",
    ")\n",
    "\n",
    "document_9 = Document(\n",
    "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
    "    metadata={\"source\": \"news\", \"category\": \"finance\"},\n",
    ")\n",
    "\n",
    "# Website/Review Content\n",
    "document_6 = Document(\n",
    "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
    "    metadata={\"source\": \"website\", \"category\": \"technology\"},\n",
    ")\n",
    "\n",
    "document_7 = Document(\n",
    "    page_content=\"The top 10 soccer players in the world right now.\",\n",
    "    metadata={\"source\": \"website\", \"category\": \"sports\"},\n",
    ")\n",
    "\n",
    "# Compile all documents into a list\n",
    "documents = [\n",
    "    document_1, document_2, document_3, document_4, document_5,\n",
    "    document_6, document_7, document_8, document_9, document_10,\n",
    "]\n",
    "\n",
    "print(f\"âœ“ Created {len(documents)} sample documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca7b2bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['27e14bf5-a894-4e42-b39a-027e818f4f60',\n",
       " '05052e9d-3933-4a17-98f8-d17954425f8b',\n",
       " '3d4c8b3d-121f-47f0-985e-5bb71947445f',\n",
       " '1a4ca509-8123-4b2c-8167-09476e02b82e',\n",
       " '415cd051-5309-4a7e-a3ab-a5eb7cd6d475',\n",
       " '26a13be2-d9c4-42b0-80d1-5c20be5232d6',\n",
       " 'd913f86b-05bb-44c3-b5df-e8fa136eaccc',\n",
       " '79f7df4f-6882-4c8e-8b33-db28b7bb8838',\n",
       " '1fd1e3e4-a699-46c6-bdb8-7280433c1996',\n",
       " 'a3eab079-7d50-428a-9a74-8751da5ff259']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Add Documents to Vector Store\n",
    "\n",
    "Upload all sample documents to the Pinecone vector database.\n",
    "This process:\n",
    "1. Generates embeddings for each document's content\n",
    "2. Stores the embeddings along with metadata in Pinecone\n",
    "3. Returns unique IDs for each stored document\n",
    "\"\"\"\n",
    "\n",
    "print(\"Adding documents to vector store...\")\n",
    "document_ids = vector_store.add_documents(documents=documents)\n",
    "print(f\"âœ“ Successfully added {len(document_ids)} documents to the vector store\")\n",
    "print(f\"Document IDs: {document_ids[:3]}...\" if len(document_ids) > 3 else f\"Document IDs: {document_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff0ebaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* LangGraph is the best framework for building stateful, agentic applications! [{'source': 'tweet'}]\n",
      "* Building an exciting new project with LangChain - come check it out! [{'source': 'tweet'}]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Perform Similarity Search with Filtering\n",
    "\n",
    "Demonstrate how to query the vector store for similar documents.\n",
    "This example searches for content related to \"LangGraph\" but only\n",
    "within documents that have source=\"tweet\".\n",
    "\n",
    "Parameters:\n",
    "- query: The search text\n",
    "- k: Number of results to return\n",
    "- filter: Metadata filtering criteria\n",
    "\"\"\"\n",
    "\n",
    "print(\"=== Similarity Search: LangGraph in Tweets ===\")\n",
    "results = vector_store.similarity_search(\n",
    "    query=\"How good is LangGraph?\",\n",
    "    k=2,                           # Return top 2 results\n",
    "    filter={\"source\": \"tweet\"},    # Only search in tweets\n",
    ")\n",
    "\n",
    "print(f\"Found {len(results)} results:\")\n",
    "for i, res in enumerate(results, 1):\n",
    "    print(f\"{i}. {res.page_content}\")\n",
    "    print(f\"   Metadata: {res.metadata}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81363edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [SIM=0.736267] The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees. [{'source': 'news'}]\n",
      "* [SIM=0.570427] The stock market is down 500 points today due to fears of a recession. [{'source': 'news'}]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Similarity Search with Similarity Scores\n",
    "\n",
    "Perform a search that returns both the matching documents and their\n",
    "similarity scores. This helps understand how closely each result\n",
    "matches the query.\n",
    "\n",
    "The similarity score ranges from 0 to 1, where:\n",
    "- 1.0 = perfect match\n",
    "- 0.0 = no similarity\n",
    "\"\"\"\n",
    "\n",
    "print(\"=== Similarity Search with Scores: Weather in News ===\")\n",
    "results = vector_store.similarity_search_with_score(\n",
    "    query=\"Will it be hot tomorrow?\", \n",
    "    k=2,                          # Return top 2 results\n",
    "    filter={\"source\": \"news\"}     # Only search in news articles\n",
    ")\n",
    "\n",
    "print(f\"Found {len(results)} results:\")\n",
    "for i, (res, score) in enumerate(results, 1):\n",
    "    print(f\"{i}. [Similarity: {score:.3f}] {res.page_content}\")\n",
    "    print(f\"   Metadata: {res.metadata}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fe5053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='1a4ca509-8123-4b2c-8167-09476e02b82e', metadata={'source': 'news'}, page_content='Robbers broke into the city bank and stole $1 million in cash.'),\n",
       " Document(id='1fd1e3e4-a699-46c6-bdb8-7280433c1996', metadata={'source': 'news'}, page_content='The stock market is down 500 points today due to fears of a recession.')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create and Use a Retriever with Score Threshold\n",
    "\n",
    "Set up a retriever that only returns documents with similarity scores\n",
    "above a specified threshold. This helps filter out irrelevant results.\n",
    "\n",
    "Configuration:\n",
    "- search_type: \"similarity_score_threshold\" - only return results above threshold\n",
    "- k: maximum number of results to return\n",
    "- score_threshold: minimum similarity score (0.4 = 40% similarity)\n",
    "\"\"\"\n",
    "\n",
    "print(\"=== Retriever with Score Threshold ===\")\n",
    "\n",
    "# Create retriever with score threshold\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\n",
    "        \"k\": 2,                    # Maximum results to return\n",
    "        \"score_threshold\": 0.4     # Minimum similarity score (40%)\n",
    "    },\n",
    ")\n",
    "\n",
    "# Perform retrieval\n",
    "print(\"Searching for: 'Stealing from the bank is a crime' in news articles...\")\n",
    "results = retriever.invoke(\"Stealing from the bank is a crime\")\n",
    "\n",
    "print(f\"Found {len(results)} results above threshold:\")\n",
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"{i}. {doc.page_content}\")\n",
    "    print(f\"   Metadata: {doc.metadata}\")\n",
    "    print()\n",
    "\n",
    "if not results:\n",
    "    print(\"No results found above the similarity threshold of 0.4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21573c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Summary and Next Steps\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. âœ“ Setting up Pinecone vector database\n",
    "2. âœ“ Creating embeddings with Google Gemini\n",
    "3. âœ“ Storing documents with metadata\n",
    "4. âœ“ Performing similarity searches\n",
    "5. âœ“ Using filters and score thresholds\n",
    "6. âœ“ Working with retrievers\n",
    "\n",
    "Next steps for production use:\n",
    "- Implement batch document processing\n",
    "- Add error handling and retry logic\n",
    "- Monitor index usage and performance\n",
    "- Set up automated index management\n",
    "- Integrate with your specific data sources\n",
    "\"\"\"\n",
    "\n",
    "print(\"ðŸŽ‰ Pinecone Vector Database Tutorial Complete!\")\n",
    "print(\"\\nKey takeaways:\")\n",
    "print(\"- Pinecone provides scalable vector storage and search\")\n",
    "print(\"- Metadata filtering enables targeted searches\")  \n",
    "print(\"- Score thresholds help maintain result quality\")\n",
    "print(\"- LangChain integration simplifies vector operations\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rag_Course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
