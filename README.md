# ğŸ”¬ RAG Course - Document Processing & Vector Embeddings R&D

A comprehensive **R&D project** implementing production-ready **Retrieval-Augmented Generation (RAG)** pipelines with advanced document processing, vector embeddings, and similarity analysis.

## ğŸ¯ Project Overview

This research project provides a complete foundation for RAG applications, covering:

- **ğŸ“„ Multi-Format Processing**: PDF, Word, CSV, Excel, JSON, and database integration
- **ğŸ§  Vector Embeddings**: OpenAI and Google Gemini integration with similarity analysis  
- **âš¡ Production Patterns**: Error handling, batch processing, and performance optimization
- **ğŸ“š Educational Content**: Comprehensive documentation and step-by-step learning modules

### ğŸ”§ Core Technologies
- **Package Manager**: [UV](https://github.com/astral-sh/uv) for fast dependency management
- **AI Framework**: LangChain with OpenAI and Google Gemini embeddings
- **Document Processing**: PyMuPDF, python-docx, pandas, sqlite3
- **Analysis**: scikit-learn, SciPy, NumPy for similarity computations

## ğŸš€ Quick Start

### Prerequisites
- **Python 3.11+** with **UV package manager** ([Install UV](https://docs.astral.sh/uv/getting-started/installation/))
- **API Keys**: OpenAI API key (optional: Google API key for Gemini)

### Setup & Installation
```bash
# Clone and setup environment
git clone https://github.com/saib7/RAG_Course.git
cd RAG_Course
uv sync                          # Install all dependencies
source .venv/bin/activate        # Activate environment

# Configure API keys
echo "OPENAI_API_KEY=your_key_here" > .env

# Start exploring
jupyter notebook                 # Launch Jupyter to explore notebooks
```

## ğŸ—ï¸ Research Modules

```
RAG_Course/
â”œâ”€â”€ ğŸ“ 1.Data_Ingest_Parsing/              # Complete document processing pipeline
â”‚   â”œâ”€â”€ ğŸ““ 1-data_ingestion.ipynb          # âœ… Document loading fundamentals  
â”‚   â”œâ”€â”€ ğŸ““ 2-data_parsing_pdf.ipynb        # âœ… Advanced PDF processing
â”‚   â”œâ”€â”€ ï¿½ 3-data_parsing_doc.ipynb        # âœ… Word document handling
â”‚   â”œâ”€â”€ ğŸ““ 4-data_parsing_csv_excel.ipynb  # âœ… Structured data processing
â”‚   â”œâ”€â”€ ï¿½ 5-data_parsing_json.ipynb       # âœ… JSON/JSONL processing  
â”‚   â”œâ”€â”€ ğŸ““ 6-data_parsing_database.ipynb   # âœ… Database integration
â”‚   â””â”€â”€ ï¿½ data/                           # Sample datasets for all formats
â”œâ”€â”€ ï¿½ 2.Vector_Embedding/                 # Vector analysis & similarity
â”‚   â”œâ”€â”€ ï¿½ 1-embeddings.ipynb              # âœ… Basic embedding concepts
â”‚   â””â”€â”€ ğŸ““ 2-openai_gemini_embeddings.ipynb # âœ… Advanced similarity analysis
â””â”€â”€ ï¿½ 0-DataIngestion_Persing/            # Initial experiments (legacy)
```

### ğŸ¯ Key Research Areas
- **ğŸ“„ Document Processing**: Complete pipeline for PDF, Word, CSV, Excel, JSON, databases
- **ğŸ§  Vector Embeddings**: OpenAI and Gemini integration with similarity analysis
- **âš¡ Performance Analysis**: Memory usage, processing time, and optimization patterns
- **ğŸ­ Production Ready**: Error handling, validation, and enterprise patterns

## ğŸ’» Usage Examples

### Document Processing
```python
# Multi-format document loading
from langchain_community.document_loaders import PyMuPDFLoader, CSVLoader, JSONLoader

# Load different document types
pdf_docs = PyMuPDFLoader("1.Data_Ingest_Parsing/data/pdf/attention.pdf").load()
csv_docs = CSVLoader("1.Data_Ingest_Parsing/data/structured_files/products.csv").load()
json_docs = JSONLoader("1.Data_Ingest_Parsing/data/json_files/company_data.json").load()
```

### Vector Embeddings & Similarity Analysis
```python
# Generate embeddings and calculate similarities
from langchain_openai import OpenAIEmbeddings
from sklearn.metrics.pairwise import cosine_similarity

embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
sentence_embeddings = embeddings.embed_documents([
    "Machine learning transforms technology",
    "AI revolutionizes computing", 
    "The weather is nice today"
])

# Calculate similarity matrix
import numpy as np
similarity_matrix = cosine_similarity(np.array(sentence_embeddings))
print("Most similar:", similarity_matrix[0][1])  # Compare first two sentences
```

## ğŸ“Š Research Highlights

### Similarity Analysis Comparison
| Method | Use Case | Performance | Implementation |
|--------|----------|-------------|----------------|
| **Manual** | Learning/Education | Slow | `np.dot(v1,v2)/(norm(v1)*norm(v2))` |
| **SciPy** | Individual pairs | Medium | `1 - cosine(v1, v2)` |
| **Scikit-learn** | Batch processing | Fast | `cosine_similarity(matrix)` |

### Document Format Coverage
- **âœ… PDF**: PyMuPDF with image extraction and metadata
- **âœ… Word**: Docx2txt and UnstructuredWord loaders  
- **âœ… Structured**: CSV/Excel with pandas integration
- **âœ… JSON**: Nested structure handling and JSONL streaming
- **âœ… Database**: SQLite with relationship preservation and security patterns

## ï¿½ï¸ Development & Extension

### Environment Management
```bash
uv sync                    # Install exact dependencies from lock file
uv add package-name        # Add new packages  
uv add --dev pytest        # Add development tools
uv lock --upgrade          # Update all dependencies
```

### Adding New Research
- **New document formats**: Extend the parsing pipeline in `1.Data_Ingest_Parsing/`
- **New embedding providers**: Add to `2.Vector_Embedding/` with comparison analysis
- **Performance optimizations**: Include benchmarking and memory usage analysis
- **Educational content**: Maintain comprehensive documentation and examples

## ğŸ“„ License & Usage

This R&D project is designed for **educational and research purposes**. All notebooks include comprehensive documentation, performance analysis, and production-ready patterns.

**Key Features:**
- ğŸ”¬ **Research-focused**: Comparative analysis and performance benchmarking
- ğŸ“š **Educational**: Step-by-step learning with detailed explanations  
- ï¿½ **Production-ready**: Error handling, validation, and optimization patterns
- âš¡ **Performance-aware**: Memory usage and processing time monitoring

---

**Start exploring:** `jupyter notebook` â†’ Navigate to `1.Data_Ingest_Parsing/1-data_ingestion.ipynb`

*Built with â¤ï¸ using UV, LangChain, OpenAI, and modern Python practices*